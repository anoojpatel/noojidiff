# noojidiff
Exploratory Implementation of Reverse-mode Autodiff with Numpy

The goal of this repository is to understand a simple implementation of autodifferentiation using reverse-mode methods and a simple tape.

The implementation will be tested on a MLP Classifier with ReLU activations. 
Simple Negative Log-likelihood Loss on a input.
Gradients of the parameters with respect ot the loss via backwardpropogation. 

It will also contain documentation attempting to walk through the proofs of correctness for why this method works.
